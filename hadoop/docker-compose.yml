version: '3.9'

services:
  kms:
    image: urykhy/hadoop
    container_name: kms
    hostname: kms
    domainname: hadoop.docker
    command: hadoop kms
    networks:
      - hadoop
    volumes:
      - hadoop_kms:/hadoop
    expose:
      - "9600"
    healthcheck:
      test: jps | grep -q KMSWebServer
      interval: 1s
      timeout: 1s
      retries: 30

  namenode:
    image: urykhy/hadoop
    container_name: namenode
    hostname: namenode
    domainname: hadoop.docker
    command: /namenode.sh
    networks:
      - hadoop
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      CLUSTER_NAME: uh-cluster
    healthcheck:
      test: curl 127.0.0.1:8020
      interval: 1s
      timeout: 1s
      retries: 30
    depends_on:
      kms:
        condition: service_healthy
    expose:
      - "8020"
      - "9870"

  datanode1:
    image: urykhy/hadoop
    container_name: datanode1
    hostname: datanode1
    domainname: hadoop.docker
    command: forego start -r -f /datanode.proc
    depends_on:
      namenode:
        condition: service_healthy
    networks:
      - hadoop
    volumes:
      - hadoop_datanode1:/hadoop/dfs/data
    healthcheck:
      test: test `jps | grep 'DataNode\|NodeManager\|JobHistoryServer' | wc -l` = '3'
      interval: 1s
      timeout: 1s
      retries: 30
    expose:
      - "8042"
      - "9864"
      - "9866"
      - "9867"
      - "19888"

  datanode2:
    image: urykhy/hadoop
    container_name: datanode2
    hostname: datanode2
    domainname: hadoop.docker
    command: forego start -r -f /datanode.proc
    depends_on:
      namenode:
        condition: service_healthy
    networks:
      - hadoop
    volumes:
      - hadoop_datanode2:/hadoop/dfs/data
    healthcheck:
      test: test `jps | grep 'DataNode\|NodeManager\|JobHistoryServer' | wc -l` = '3'
      interval: 1s
      timeout: 1s
      retries: 30
    expose:
      - "8042"
      - "9864"
      - "9866"
      - "9867"
      - "19888"

  resourcemanager:
    image: urykhy/hadoop
    container_name: resourcemanager
    hostname: resourcemanager
    domainname: hadoop.docker
    command: forego start -r -f /resourcemanager.proc
    depends_on:
      datanode1:
        condition: service_healthy
      datanode2:
        condition: service_healthy
    networks:
      - hadoop
    expose:
      - "8088"
    healthcheck:
      test: jps | grep -q ResourceManager
      interval: 1s
      timeout: 1s
      retries: 30

  historyserver:
    image: urykhy/hadoop
    container_name: historyserver
    hostname: historyserver
    domainname: hadoop.docker
    command: yarn timelineserver
    depends_on:
      datanode1:
        condition: service_healthy
      datanode2:
        condition: service_healthy
    networks:
      - hadoop
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    expose:
      - "8188"
    healthcheck:
      test: jps | grep -q ApplicationHistoryServer
      interval: 1s
      timeout: 1s
      retries: 30

  minio:
    image: urykhy/hadoop
    container_name: minio-hdfs
    hostname: minio
    domainname: hadoop.docker
    depends_on:
      datanode1:
        condition: service_healthy
      datanode2:
        condition: service_healthy
    networks:
    - hadoop
    environment:
      MINIO_ACCESS_KEY: minio
      MINIO_SECRET_KEY: minio123
      KRB5USERNAME: minio
      KRB5REALM: KERBEROS.ELF.DARK
      KRB5KEYTAB: /etc/minio.keytab
    command: bash -c "minio gateway hdfs hdfs://namenode.hadoop.docker:8020 --console-address :9009"
    volumes:
      - hadoop_minio:/data
    expose:
      - "9000"
      - "9009"

  spark:
    image: urykhy/hadoop-spark
    container_name: spark
    hostname: spark
    domainname: hadoop.docker
    networks:
      - hadoop
    command: ./bin/spark-class org.apache.spark.deploy.history.HistoryServer
    depends_on:
      - namenode
    profiles: ["spark"]
    healthcheck:
      test: jps | grep -q HistoryServer
      interval: 1s
      timeout: 1s
      retries: 30

networks:
  hadoop:
    external: true

volumes:
  hadoop_kms:
    external: true
  hadoop_namenode:
    external: true
  hadoop_datanode1:
    external: true
  hadoop_datanode2:
    external: true
  hadoop_historyserver:
    external: true
  hadoop_minio:
    external: true
